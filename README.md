# Covid-19-Prediction-and-Analysis-Using-ML-
Human when communicate they use emotion to convey their message to each other clearly so we can say that emotion is equally important as the content said by humans. The role of emotion in the context which defines the message led to the demand of emotion recognition system and expansion that idea led to demand of human computer interaction system. The advances that were made in Machine learning field lead by many researchers and the requirement of real time speech emotion recognition system for the human computer interaction led to the creation of many datasets and methods to achieve and better the accuracy or existing solution for emotion recognition in speech. Human emotion is very complex in nature and due to which, what feature we select can have major impact on our machine learning model outcome. My work led me to explore many machine learning methods and feature extraction methods for creation of speech emotion recognition system. In this paper we are going to understand and see the approaches discovered by me throughout	our	major	project.

A great deal of multidisciplinary study has been done which went into understanding speech emotion detection throughout the years. Researchers in the neuroscience field study how the brain receives incoming stimuli by analysing raw audio data. Linguists would rather observe speech that can supply emotional information through semantic and syntactic analysis of the speech, but computational intelligence researchers provide tools to explain the knowledge received from neuroscientists in a mathematical solution. These multidisciplinary research collaborations have showed enormous promise in comprehending voice emotion.
The starting of SER was from psychology not from computer science field as some scientist researched the role of acoustics of human emotion, that is what is the effect of emotion upon the voice which is understood by other people. It was found that the most primitive emotion example love, and anger can be understood by most primitive people which is also shared with animals alike. The language of tone is most common and oldest in our civilization. The idea for letting computer understand the emotion was lead two decades before at the same time when machine learning was also being popular, and many people was discovering many new machine learning methods. Now after two decade of research we can say that speech emotion recognition is matured enough so that major advancement can be done in this area. In todayâ€™s world there are lot data created by humans which can help us to create good dataset which can used to train model in deep learning. Our report is based on speech emotion recognition that is recognition of emotion by computer and to put it more accurately we can say that enabling computers to recognise emotion from the acoustic characteristics from the speech like pitch, tone, loudness, and spectral distribution of frequency. However, recognising emotions from speech is a difficult process. First and foremost, even for the same feeling, there is unlimited diversity in emotional responses inside and across speakers. The diversity of emotions is another aspect. People may shade or conceal their emotions because they are complex or because of societal factors. Information must be distinguished from other impacts on the voice, such as vocal abnormalities, breathing sound and physical ambiance sound.
 
There is also a high demand for Voise based system, a computer system which
uses intelligence system to mimic emotion and read the content. For computer to understand the emotion and to mimic is quite hard to build so much research is going on in this field which can be also helper or reinforced by emotion recognition system. Speech emotion detection is challenging due to the nature of emotion and complexity build by people around the world and their culture. Which is solved by using machine learning method to classify the emotion in speech. What has been accomplished thus far is the recognition of clearly expressed performed emotions with excellent accuracy, but still real- world dataset is not created and still we are not able to identify emotion in real time in social environment. Prediction accuracies are based not only on emotion types, but also on the number of emotion classes: from performed emotion, up to eight emotion classes have been effectively identified, but from natural emotions, only five classes can be meaningfully categorized, and even these with accuracies below 50%. The proposed approach has been proven to work on both men and women as well as children. However, thus far, technology has mostly been used
in laboratory settings with a peaceful background and a solitary clearly loud s
	<h3>Objective<h3>
The main goal and objective for the project undertaken are to create speech Emotion Recognition (SER) to aid human to machine interaction with the help of recently advanced machine learning techniques. Machine learning methods has improved very fast in a short period. With present deep learning methods, we can train our model with huge dataset and implement data augmentation techniques or multi-layer models to increase the accuracy of our model. Also, to provides for simple application integration so we can widen the use of speech emotion recognition application in the world.
